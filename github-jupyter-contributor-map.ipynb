{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the GitHub API for repositories and organizations\n",
    "By Stuart Geiger and Jamie Whitacre, made at a SciPy 2016 sprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): pygithub in /home/mam/anaconda3/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): geopy in /home/mam/anaconda3/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): ipywidgets in /home/mam/anaconda3/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): ipykernel>=4.2.2 in /home/mam/anaconda3/lib/python3.5/site-packages (from ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): widgetsnbextension>=1.2.6 in /home/mam/anaconda3/lib/python3.5/site-packages (from ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): traitlets>=4.2.1 in /home/mam/anaconda3/lib/python3.5/site-packages (from ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): ipython>=4.0.0 in /home/mam/anaconda3/lib/python3.5/site-packages (from ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): notebook>=4.2.0 in /home/mam/notebook (from widgetsnbextension>=1.2.6->ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): jinja2 in /home/mam/anaconda3/lib/python3.5/site-packages (from notebook>=4.2.0->widgetsnbextension>=1.2.6->ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): tornado>=4 in /home/mam/anaconda3/lib/python3.5/site-packages (from notebook>=4.2.0->widgetsnbextension>=1.2.6->ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): ipython_genutils in /home/mam/anaconda3/lib/python3.5/site-packages (from notebook>=4.2.0->widgetsnbextension>=1.2.6->ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): jupyter_core in /home/mam/anaconda3/lib/python3.5/site-packages (from notebook>=4.2.0->widgetsnbextension>=1.2.6->ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): jupyter_client in /home/mam/anaconda3/lib/python3.5/site-packages (from notebook>=4.2.0->widgetsnbextension>=1.2.6->ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): nbformat in /home/mam/anaconda3/lib/python3.5/site-packages (from notebook>=4.2.0->widgetsnbextension>=1.2.6->ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): nbconvert in /home/mam/anaconda3/lib/python3.5/site-packages (from notebook>=4.2.0->widgetsnbextension>=1.2.6->ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): terminado>=0.3.3 in /home/mam/anaconda3/lib/python3.5/site-packages (from notebook>=4.2.0->widgetsnbextension>=1.2.6->ipywidgets)\n",
      "Requirement already satisfied (use --upgrade to upgrade): MarkupSafe in /home/mam/anaconda3/lib/python3.5/site-packages (from jinja2->notebook>=4.2.0->widgetsnbextension>=1.2.6->ipywidgets)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygithub\n",
    "!pip install geopy\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from github import Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is my private login credentials, stored in ghlogin.py\n",
    "import ghlogin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = Github(login_or_token=ghlogin.gh_user, password=ghlogin.gh_passwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With this Github object, you can get all kinds of Github objects, which you can then futher explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = g.get_user(\"staeiou\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stuart Geiger\n",
      "2013-06-14 00:25:39\n",
      "Berkeley, CA\n"
     ]
    }
   ],
   "source": [
    "print(user.name)\n",
    "print(user.created_at)\n",
    "print(user.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repo = g.get_repo(\"jupyter/notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook\n",
      "Jupyter Interactive Notebook\n",
      "<github.Organization.Organization object at 0x7f5889b06cf8>\n",
      "Project Jupyter\n",
      "JavaScript\n"
     ]
    }
   ],
   "source": [
    "print(repo.name)\n",
    "print(repo.description)\n",
    "print(repo.organization)\n",
    "print(repo.organization.name)\n",
    "print(repo.language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<github.PaginatedList.PaginatedList object at 0x7f589fe2c630>\n"
     ]
    }
   ],
   "source": [
    "print(repo.get_commits())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthias Bussonnier\n",
      "Merge pull request #1603 from minrk/rm-docker-readme\n",
      "\n",
      "remove outdated/false docker info from README\n",
      "0\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "commits = repo.get_commits()\n",
    "commit = commits[0]\n",
    "print(commit.author.name)\n",
    "print(commit.commit.message)\n",
    "print(commit.stats.additions)\n",
    "print(commit.stats.deletions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Organizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizations are objects too, which have similar properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "org = g.get_organization(\"jupyter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Jupyter\n",
      "2014-04-23 21:36:43\n",
      "https://github.com/jupyter\n"
     ]
    }
   ],
   "source": [
    "print(org.name)\n",
    "print(org.created_at)\n",
    "print(org.html_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API has a get_public_members() function, but it just shows those who are on the \"people\" board on the [organization's page](https://github.com/jupyter). You can also see that if someone doesn't have a field set, it returns None. Some people just have usernames set without full names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthias Bussonnier https://api.github.com/users/Carreau\n",
      "JamieW https://api.github.com/users/JamiesHQ\n",
      "Corey Stubbs https://api.github.com/users/Lull3rSkat3r\n",
      "Sylvain Corlay https://api.github.com/users/SylvainCorlay\n",
      "Afshin Darian https://api.github.com/users/afshin\n",
      "Steven Silvester https://api.github.com/users/blink1073\n",
      "Safia Abdalla https://api.github.com/users/captainsafia\n",
      "Dave Willmer https://api.github.com/users/dwillmer\n",
      "Fernando Perez https://api.github.com/users/fperez\n",
      "Paul Ivanov https://api.github.com/users/ivanov\n",
      "None https://api.github.com/users/jakirkham\n",
      "Jason Grout https://api.github.com/users/jasongrout\n",
      "Jonathan Frederic https://api.github.com/users/jdfreder\n",
      "Jessica B. Hamrick https://api.github.com/users/jhamrick\n",
      "Min RK https://api.github.com/users/minrk\n",
      "Peter Parente https://api.github.com/users/parente\n",
      "Mike https://api.github.com/users/poplav\n",
      "Kyle Kelley https://api.github.com/users/rgbkrk\n",
      "Sumit Sahrawat https://api.github.com/users/sumitsahrawat\n",
      "Thomas Kluyver https://api.github.com/users/takluyver\n",
      "Carol Willing https://api.github.com/users/willingc\n"
     ]
    }
   ],
   "source": [
    "for member in org.get_public_members():\n",
    "    print(member.name, member.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go through all the repositories in the organization with the get_repos() function. It returns a list of repository objects, which have their own properties and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbviewer Nbconvert as a webservice (rendering ipynb to static HTML)\n",
      "nbconvert-examples Examples that illustrate how nbconvert can be used\n",
      "colaboratory Jupyter CoLaboratory\n",
      "jupyter.github.io Jupyter Website\n",
      "design Design related materials for Project Jupyter\n",
      "nbcache Notebook Caching layer in Docker\n",
      "nbgrader A system for assigning and grading notebooks\n",
      "tmpnb Creates temporary Jupyter Notebook servers using Docker containers.\n",
      "nature-demo Materials for the November 2014 Nature Article\n",
      "jupyter-drive Google drive for jupyter notebooks\n",
      "tmpnb-redirector Simple HTTP redirector for tmpnb nodes\n",
      "tmpnb-deploy Deploying tmpnb nodes\n",
      "docker-demo-images Demo images for use in try.jupyter.org and tmpnb.org\n",
      "try.jupyter.org Try Jupyter!\n",
      "strata-sv-2015-tutorial Strata Silicon Valley 2015 Tutorial\n",
      "testpath Test utilities for Python code working with files and commands\n",
      "scipy-2015-advanced-topics Advanced topics in Jupyter tutorial for SciPy 2015.\n",
      "jupyter_core Core Jupyter functionality\n",
      "nbformat Reference implementation of the Jupyter Notebook format\n",
      "jupyter_client Jupyter protocol client APIs\n",
      "notebook Jupyter Interactive Notebook\n",
      "nbconvert Jupyter Notebook Conversion\n",
      "jupyter_console Jupyter Terminal Console\n",
      "qtconsole Jupyter Qt Console\n",
      "jupyter_logger Allows you to log Jupyter notebook user events anonymously.\n",
      "jupyter_kernel_test A tool for testing Jupyter kernels\n",
      "jupyter Jupyter metapackage for installation, docs and chat\n",
      "ngcm-tutorial Materials for the IPython/Jupyter workshop at the NGCM Summer Academy, at Southampton University, Boldrewood campus.\n",
      "scipy-advanced-tutorial Advance Tutorial For SciPy\n",
      "docker-stacks Opinionated stacks of ready-to-run Jupyter applications in Docker.\n",
      "lbnl-jupyterday Materials for the Jupyter workshop at LBNL, 17 July 2015\n",
      "jupyter-js-services Javascript client for the Jupyter services REST APIs\n",
      "atom-notebook Jupyter Notebook, but inside Atom.\n",
      "enhancement-proposals Enhancement proposals for the Jupyter Ecosystem\n",
      "governance The governance process and model for Project Jupyter\n",
      "jupyter-blog-theme Backup of blog.jupyter.org\n",
      "kernel_gateway Jupyter Kernel Gateway\n",
      "cdn.jupyter.org Assets and layout for cdn.jupyter.org\n",
      "roadmap Master roadmap for Project Jupyter\n",
      "mozfest15-training Notebooks for Jupyter training session at Mozfest 2015\n",
      "nbdime Tools for diffing and merging of Jupyter notebooks.\n",
      "jupyter-js-utils JavaScript utilities for the Jupyter frontend\n",
      "kernel_gateway_demos Demos associated with the kernel gateway incubator project\n",
      "newsletter A repo for collecting content for the Jupyter Newsletter\n",
      "jupyter-sphinx-theme A Sphinx theme for Jupyter and IPython documentation\n",
      "help :sparkles: Need some help or have some questions? Open an issue here. :sparkles:\n",
      "widget-cookiecutter A cookiecutter template for creating a custom Jupyter widget project.\n",
      "surveys Surveys and datasets collected by Project Jupyter\n",
      "jupyterlab JupyterLab computational environment. This is a very early preview, and is not suitable for general usage yet.\n",
      "experiments \n",
      "jupyterhub-2016-workshop Materials for an online mini-workshop around JupyterHub use cases, held July 22nd, 2016\n",
      "jupyter-sprints Resources for running a sprint\n",
      "scipy-sprint Sprint organization and planning\n"
     ]
    }
   ],
   "source": [
    "for repo in org.get_repos():\n",
    "    print(repo.name, repo.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate limiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that we have made a few requests, we can see what our rate limit is. If you are logged in, you get 5,000 requests per hour. If you are not, you only get 60 per hour. You can use methods in the GitHub object to see your limit, usage, and reset time. We have used less than 50 of our 5,000 requests with these calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4969, 5000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.rate_limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1468970425"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_time = g.rate_limiting_resettime\n",
    "reset_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is in seconds since the UTC epoch (Jan 1st, 1970), so we have to convert it. Here is a quick function that takes a GitHub object, queries the API to find our next reset time, and converts it to minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def minutes_to_reset(github):\n",
    "    github.rate_limiting_resettime\n",
    "    timedelta_to_reset = datetime.datetime.fromtimestamp(reset_time) - datetime.datetime.now()\n",
    "    return timedelta_to_reset.seconds / 60\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minutes_to_reset(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting location data for an organization's contributors\n",
    "### Mapping and geolocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "Before we get into how to query GitHub, we know we will have to get location coordinates for each contributor, and then plot it on a map. So we are going to do that first.\n",
    "\n",
    "For geolocation, we are using geopy's geolocator object, which is based on Open Street Map's Nominatim API. Nominatim takes in any arbitrary location data and then returns a location object, which includes the best latitude and longitude coordinates it can find. \n",
    "\n",
    "This does mean that we will have more error than if we did this manually, and there might be vastly different levels of accuracy. For example, if someone just has \"UK\" as their location, it will show up in the geographic center of the UK, which is somewhere on the edge of the Lake District. \"USA\" resolves to somewhere in Kansas. However, you can get very specific location data if you put in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.2765752 54.7023545\n",
      "-100.4458824 39.7837304\n",
      "-122.259492086406 37.87219435\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim()\n",
    "uk_loc = geolocator.geocode(\"UK\")\n",
    "print(uk_loc.longitude,uk_loc.latitude)\n",
    "\n",
    "us_loc = geolocator.geocode(\"USA\")\n",
    "print(us_loc.longitude,us_loc.latitude)\n",
    "\n",
    "bids_loc = geolocator.geocode(\"Doe Library, Berkeley CA, 94720 USA\")\n",
    "print(bids_loc.longitude,bids_loc.latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot points on a map using ipyleaflets and ipywidgets. We first set up a map object, which is created with various parameters. Then we create Marker objects, which are then appended to the map. We then display the map inline in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl\n",
    ")\n",
    "\n",
    "center = [30.0, 5.0]\n",
    "zoom = 2\n",
    "m = Map(default_tiles=TileLayer(opacity=1.0), center=center, zoom=zoom, layout=ipywidgets.Layout(height=\"600px\"))\n",
    "\n",
    "uk_mark = Marker(location=[uk_loc.latitude,uk_loc.longitude])\n",
    "uk_mark.visible\n",
    "m += uk_mark\n",
    "\n",
    "us_mark = Marker(location=[us_loc.latitude,us_loc.longitude])\n",
    "us_mark.visible\n",
    "m += us_mark\n",
    "\n",
    "bids_mark = Marker(location=[bids_loc.latitude,bids_loc.longitude])\n",
    "bids_mark.visible\n",
    "m += bids_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying GitHub for location data\n",
    "\n",
    "For our mapping script, we want to get profiles for everyone who has made a commit to any of the repositories in the Jupyter organization, find their location (if any), then add it to a list. The API has a get_contributors function for repo objects, which returns a list of contributors ordered by number of commits, but not one that works across all repos in an org. So we have to iterate through all the repos in the org, and run the get_contributors method for We also want to make sure we don't add any duplicates to our list to over-represent any areas, so we keep track of people in a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've written a few functions to make it easy to retreive and map an organization's contributors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_org_contributor_locations(github, org_name):\n",
    "    \"\"\"\n",
    "    For a GitHub organization, get location for contributors to any repo in the org.\n",
    "    \n",
    "    Returns a dictionary of {username URLS : geopy Locations}, then a dictionary of various metadata.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up empty dictionaries and metadata variables\n",
    "    contributor_locs = {}\n",
    "    locations = []\n",
    "    none_count = 0\n",
    "    error_count = 0\n",
    "    user_loc_count = 0\n",
    "    duplicate_count = 0\n",
    "    geolocator = Nominatim()\n",
    "\n",
    "    \n",
    "    # For each repo in the organization\n",
    "    for repo in github.get_organization(org_name).get_repos():\n",
    "        #print(repo.name)\n",
    "        \n",
    "        # For each contributor in the repo        \n",
    "        for contributor in repo.get_contributors():\n",
    "            print('.', end=\"\")\n",
    "            # If the contributor_locs dictionary doesn't have an entry for this user\n",
    "            if contributor_locs.get(contributor.url) is None:\n",
    "                \n",
    "                # Try-Except block to handle API errors\n",
    "                try:\n",
    "                    # If the contributor has no location in profile\n",
    "                    if(contributor.location is None):\n",
    "                        #print(\"No Location\")\n",
    "                        none_count += 1\n",
    "                    else:\n",
    "                        # Get coordinates for location string from Nominatim API\n",
    "                        location=geolocator.geocode(contributor.location)\n",
    "\n",
    "                        #print(contributor.location, \" | \", location)\n",
    "                        \n",
    "                        # Add a new entry to the dictionary. Value is user's URL, key is geocoded location object\n",
    "                        contributor_locs[contributor.url] = location\n",
    "                        user_loc_count += 1\n",
    "                except Exception:\n",
    "                    print('!', end=\"\")\n",
    "                    error_count += 1\n",
    "            else:\n",
    "                duplicate_count += 1\n",
    "                \n",
    "    return contributor_locs,{'no_loc_count':none_count, 'user_loc_count':user_loc_count, \n",
    "                             'duplicate_count':duplicate_count, 'error_count':error_count}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can easily query an organization. The U.D. Digital Service (org name: usds) is a small org that works well for testing. It takes about a second per contributor to get this data, so we want to test on small orgs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................."
     ]
    }
   ],
   "source": [
    "usds_locs, usds_metadata = get_org_contributor_locations(g,'usds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duplicate_count': 1,\n",
       " 'error_count': 0,\n",
       " 'no_loc_count': 8,\n",
       " 'user_loc_count': 22}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usds_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to explore this dataset, but not plot names or usernames. I'm a bit hesitant to publish location data with unique identifiers, even if people put that information in their profiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Location(Portland, Multnomah County, Oregon, United States of America, (45.5202471, -122.6741948, 0.0)),\n",
       " Location(東京都, 日本, (34.2255804, 139.294774527387, 0.0)),\n",
       " Location(D,C, Buccaneer Ridge Drive, Johnson City, Washington County, Tennessee, 37614, United States of America, (36.29885175, -82.3591932141095, 0.0)),\n",
       " Location(Washington, District of Columbia, United States of America, (38.8949549, -77.0366455, 0.0)),\n",
       " Location(Oakland, Alameda County, California, United States of America, (37.8044557, -122.2713562, 0.0)),\n",
       " Location(Washington, District of Columbia, United States of America, (38.8949549, -77.0366455, 0.0)),\n",
       " Location(Dayton, Montgomery County, Ohio, United States of America, (39.7589478, -84.1916068, 0.0)),\n",
       " Location(Washington, District of Columbia, United States of America, (38.8949549, -77.0366455, 0.0)),\n",
       " Location(SF, California, United States of America, (37.7792808, -122.4192362, 0.0)),\n",
       " Location(Milwaukee, Milwaukee County, Wisconsin, United States of America, (43.0349931, -87.9224969, 0.0)),\n",
       " Location(Brooklyn Basin, Oakland, Alameda County, California, United States of America, (37.7857615, -122.24858, 0.0)),\n",
       " Location(Seattle, King County, Washington, United States of America, (47.6038321, -122.3300623, 0.0)),\n",
       " Location(D,C, Buccaneer Ridge Drive, Johnson City, Washington County, Tennessee, 37614, United States of America, (36.29885175, -82.3591932141095, 0.0)),\n",
       " Location(Falls Church, Falls Church City, Virginia, United States of America, (38.882334, -77.1710913, 0.0)),\n",
       " Location(Washington, District of Columbia, United States of America, (38.8949549, -77.0366455, 0.0)),\n",
       " Location(SF, California, United States of America, (37.7792808, -122.4192362, 0.0)),\n",
       " Location(Washington, District of Columbia, United States of America, (38.8949549, -77.0366455, 0.0)),\n",
       " Location(United States of America, (39.7837304, -100.4458824, 0.0)),\n",
       " Location(Alexandria, Alexandria City, Virginia, United States of America, (38.8051095, -77.0470228, 0.0)),\n",
       " Location(SF, California, United States of America, (37.7792808, -122.4192362, 0.0)),\n",
       " Location(Washington, District of Columbia, United States of America, (38.8949549, -77.0366455, 0.0)),\n",
       " Location(Port Angeles, Clallam County, Washington, United States of America, (48.118146, -123.4307412, 0.0))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usds_locs_nousernames = []\n",
    "for contributor, location in usds_locs.items():\n",
    "    usds_locs_nousernames.append(location)\n",
    "usds_locs_nousernames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can map this data using another function I have written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_location_dict(map_obj,org_location_dict):\n",
    "    \"\"\"\n",
    "    Maps the locations in a dictionary of {ids : geoPy Locations}. \n",
    "    \n",
    "    Must be passed a map object, then the dictionary. Returns the map object.\n",
    "    \n",
    "    \"\"\"\n",
    "    for username, location in org_location_dict.items():\n",
    "        if(location is not None):\n",
    "            mark = Marker(location=[location.latitude,location.longitude])\n",
    "            mark.visible\n",
    "            map_obj += mark\n",
    "            \n",
    "\n",
    "    return map_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "center = [30.0,5.0]\n",
    "zoom = 2\n",
    "usds_map = Map(default_tiles=TileLayer(opacity=1.0), center=center, zoom=zoom, layout=ipywidgets.Layout(height=\"600px\"))\n",
    "\n",
    "usds_map = map_location_dict(usds_map, usds_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usds_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping multiple organizations\n",
    "Sometimes you have multiple organizations within a group of interest. Because these are functions, they can be combined with some loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jupyter_orgs = ['jupyter', 'ipython', 'jupyter-attic','jupyterhub']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter\n",
      "ipython\n",
      "jupyter-attic\n",
      "jupyterhub\n"
     ]
    }
   ],
   "source": [
    "orgs_location_dict = {}\n",
    "orgs_metadata_dict = {}\n",
    "for org in jupyter_orgs:\n",
    "    # For a status update, print when we get to a new org in the list\n",
    "    print(org)\n",
    "    orgs_location_dict[org], orgs_metadata_dict[org] = get_org_contributor_locations(g,org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ipython': {'duplicate_count': 185,\n",
       "  'error_count': 1,\n",
       "  'no_loc_count': 307,\n",
       "  'user_loc_count': 314},\n",
       " 'jupyter': {'duplicate_count': 322,\n",
       "  'error_count': 0,\n",
       "  'no_loc_count': 273,\n",
       "  'user_loc_count': 322},\n",
       " 'jupyter-attic': {'duplicate_count': 33,\n",
       "  'error_count': 0,\n",
       "  'no_loc_count': 39,\n",
       "  'user_loc_count': 29},\n",
       " 'jupyterhub': {'duplicate_count': 35,\n",
       "  'error_count': 0,\n",
       "  'no_loc_count': 27,\n",
       "  'user_loc_count': 46}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orgs_metadata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "center = [30, 5]\n",
    "zoom = 2\n",
    "jupyter_orgs_maps = Map(default_tiles=TileLayer(opacity=1.0), center=center, zoom=zoom, \n",
    "                        layout=ipywidgets.Layout(height=\"600px\"))\n",
    "\n",
    "for org_name,org_location_dict in orgs_location_dict.items():\n",
    "    jupyter_orgs_maps += map_location_dict(jupyter_orgs_maps,org_location_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jupyter_orgs_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def org_dict_to_csv(org_location_dict, filename, hashed_usernames = True):\n",
    "    \"\"\"\n",
    "    Outputs a dict of users : locations to a CSV file. \n",
    "    \n",
    "    Requires org_location_dict and filename, optional hashed_usernames parameter.\n",
    "    \n",
    "    Uses hashes of usernames by default for privacy reasons. Think carefully \n",
    "    about publishing location data about uniquely identifiable users. Hashing\n",
    "    allows you to check unique users without revealing personal information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import hashlib\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(\"user, longitude, latitude\\n\")\n",
    "            for user, location in org_location_dict.items():\n",
    "                if location is not None:\n",
    "                    if hashed_usernames:\n",
    "                        user_output = hashlib.sha1(user.encode('utf-8')).hexdigest()\n",
    "                    else:\n",
    "                        user_output = user\n",
    "                    line = user_output + \", \" + str(location.longitude) + \", \" \\\n",
    "                           + str(location.latitude) + \"\\n\"\n",
    "                    f.write(line)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "org_dict_to_csv(orgs_location_dict['ipython'], \"org_data/ipython.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for org_name, org_location_dict in orgs_location_dict.items():\n",
    "    org_dict_to_csv(org_location_dict, \"org_data/\" + org_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_org_dict(filename):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: Write function to read an outputted CSV file back to an org_dict.\n",
    "    Should convert lon/lat pairs to geopy Location objects for full compatibility.\n",
    "    \n",
    "    Also, think about a general class object for org_dicts. \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this will have duplicates across the organizations, as it is just getting the location data from each of the organizations and putting it into a different dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {
    "79a5c84646834f3ea44bf1035bfde152": {
     "views": [
      {
       "cell_index": 56
      }
     ]
    },
    "bd681adb803d4328a88523b2215daee2": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
